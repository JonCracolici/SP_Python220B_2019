Some code restructuring was first done on the linear version. 
-This made sure the outputs matched what was asked for in the assignments
-Eliminated the try-except and error counting needed for lesson 5 because that was not necessary for this part
-Made a function that added any .csv input to its respective database (ratherthan doing all three separately)

Parallel runnining was accomplished using the threading module.

Modified input/test data to go out to line 1000 in Excel (999 entries in each)

Contention was avoided by using the .join() module so that any of the individual threads cannot be modified further until the previous task completes 

linear.py was run 3x with total time = 1.0647996160000002, average 0.3549332053333334 seconds per run
With this output on the third run: ((999, 7992, 8991, 0.34139299392700195), (999, 7992, 8991, 0.34139299392700195))
The before number increased each run because the database was not cleared between runs. I don't think this substantially affects timing

parallel.py was run 3x time = 0.986690715, average 0.328896905 seconds per run
With this output on the third run: ((999, 10989, 11988, 0.4483177661895752), (999, 10989, 11988, 0.4483177661895752))

Parallel runs got a 7% speed improvement here. This isn't a massive improvement but could be more substantial with a larger database/entries to get through.

This was fairly simple to implement I would recommend switching to parallel to management.