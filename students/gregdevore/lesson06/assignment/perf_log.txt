Here is my first run of cProfile on 'poor_perf.py', ordered by cumulative time

1029624 function calls (1029607 primitive calls) in 3.894 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   3/1    0.000    0.000    3.894    3.894 {built-in method builtins.exec}
     1    0.000    0.000    3.894    3.894 poor_perf.py:4(<module>)
     1    0.078    0.078    3.891    3.891 poor_perf.py:59(main)
     1    3.710    3.710    3.812    3.812 poor_perf.py:9(analyze)
1000012    0.073    0.000    0.073    0.000 {method 'append' of 'list' objects}
 14018    0.011    0.000    0.029    0.000 codecs.py:318(decode)
 14018    0.017    0.000    0.017    0.000 {built-in method _codecs.utf_8_decode}
   5/2    0.000    0.000    0.003    0.002 <frozen importlib._bootstrap>:966(_find_and_load)
   5/2    0.000    0.000    0.003    0.002 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)
   5/2    0.000    0.000    0.003    0.001 <frozen importlib._bootstrap>:651(_load_unlocked)
     2    0.000    0.000    0.003    0.001 <frozen importlib._bootstrap_external>:672(exec_module)
   8/2    0.000    0.000    0.002    0.001 <frozen importlib._bootstrap>:211(_call_with_frames_removed)
     1    0.000    0.000    0.002    0.002 datetime.py:5(<module>)


Right away, I notice that the 'append' method is being called over 1 million
times (probably once per line of the CSV file). Perhaps this part of the code
could be better structured.

After looking at the code, on line 15, the row returned by the CSV reader is
already a list, so the list conversion step is not needed.

1029116 function calls (1029099 primitive calls) in 3.360 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   3/1    0.000    0.000    3.360    3.360 {built-in method builtins.exec}
     1    0.000    0.000    3.360    3.360 good_perf.py:4(<module>)
     1    0.085    0.085    3.357    3.357 good_perf.py:57(main)
     1    3.174    3.174    3.272    3.272 good_perf.py:9(analyze)
1000012    0.071    0.000    0.071    0.000 {method 'append' of 'list' objects}
 13764    0.010    0.000    0.026    0.000 codecs.py:318(decode)
 13764    0.017    0.000    0.017    0.000 {built-in method _codecs.utf_8_decode}
   5/2    0.000    0.000    0.003    0.002 <frozen importlib._bootstrap>:966(_find_and_load)
   5/2    0.000    0.000    0.003    0.002 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)
   5/2    0.000    0.000    0.003    0.001 <frozen importlib._bootstrap>:651(_load_unlocked)
     2    0.000    0.000    0.003    0.001 <frozen importlib._bootstrap_external>:672(exec_module)
   8/2    0.000    0.000    0.002    0.001 <frozen importlib._bootstrap>:211(_call_with_frames_removed)

The performance has already improved by 0.5 seconds.

Next, the creation of a new list for dates after 2012 is not needed. Removing
this would eliminate the all of the append calls. Also, the expression
"lrow[5] > '00/00/2012'" is meaningless, so I'll replace it with a simple
check to make sure the year is greater than 2012 (so as to not generate a
key error when keeping track of year counts).

35351 function calls (35211 primitive calls) in 2.224 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
  11/1    0.000    0.000    2.224    2.224 {built-in method builtins.exec}
     1    0.000    0.000    2.224    2.224 good_perf.py:4(<module>)
     1    0.000    0.000    2.210    2.210 good_perf.py:52(main)
     1    2.186    2.186    2.210    2.210 good_perf.py:24(analyze)
 14018    0.009    0.000    0.023    0.000 codecs.py:318(decode)
 14018    0.015    0.000    0.015    0.000 {built-in method _codecs.utf_8_decode}
  14/3    0.000    0.000    0.014    0.005 <frozen importlib._bootstrap>:966(_find_and_load)
  14/3    0.000    0.000    0.014    0.005 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)
  14/3    0.000    0.000    0.013    0.004 <frozen importlib._bootstrap>:651(_load_unlocked)
   9/3    0.000    0.000    0.013    0.004 <frozen importlib._bootstrap_external>:672(exec_module)
  19/3    0.000    0.000    0.011    0.004 <frozen importlib._bootstrap>:211(_call_with_frames_removed)

The performance improved again by over one second, and the total number
of function calls is down to 35,000.

Now, the next place to improve is the fact that the entire file is read twice.
I went ahead and merged everything into one read.

15601 function calls (15584 primitive calls) in 1.285 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   3/1    0.000    0.000    1.285    1.285 {built-in method builtins.exec}
     1    0.000    0.000    1.285    1.285 good_perf.py:4(<module>)
     1    0.000    0.000    1.280    1.280 good_perf.py:30(main)
     1    1.267    1.267    1.280    1.280 good_perf.py:9(analyze)
  7009    0.005    0.000    0.013    0.000 codecs.py:318(decode)
  7009    0.008    0.000    0.008    0.000 {built-in method _codecs.utf_8_decode}
   5/2    0.000    0.000    0.004    0.002 <frozen importlib._bootstrap>:966(_find_and_load)
   5/2    0.000    0.000    0.004    0.002 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)
   5/2    0.000    0.000    0.004    0.002 <frozen importlib._bootstrap>:651(_load_unlocked)
     2    0.000    0.000    0.004    0.002 <frozen importlib._bootstrap_external>:672(exec_module)
   8/2    0.000    0.000    0.003    0.002 <frozen importlib._bootstrap>:211(_call_with_frames_removed)
     1    0.000    0.000    0.002    0.002 datetime.py:5(<module>)
     5    0.000    0.000    0.002    0.000 <frozen importlib._bootstrap>:564(module_from_spec)
     3    0.000    0.000    0.002    0.001 <frozen importlib._bootstrap_external>:919(create_module)
     3    0.002    0.001    0.002    0.001 {built-in method _imp.create_dynamic}

 The performance has again improved by over one second, and the number of function
 calls has been more than halved.
