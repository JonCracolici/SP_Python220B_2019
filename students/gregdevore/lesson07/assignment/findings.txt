1. The following is the output from linear.py:

(1000, 0, 1000, 0.05919623374938965)
(1000, 0, 1000, 0.053708791732788086)
(1000, 0, 1000, 0.061570167541503906)
Total elapsed time: 0.222738 seconds

Running cProfile on linear.py produces the following:

216308 function calls (214333 primitive calls) in 0.353 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
 138/1    0.007    0.000    0.353    0.353 {built-in method builtins.exec}
     1    0.001    0.001    0.353    0.353 linear.py:4(<module>)
     3    0.000    0.000    0.141    0.047 linear.py:93(add_json_to_mongodb)
     3    0.000    0.000    0.129    0.043 collection.py:701(insert_many)
    20    0.000    0.000    0.123    0.006 network.py:192(receive_message)
    40    0.000    0.000    0.122    0.003 network.py:249(_receive_data_on_socket)
    40    0.122    0.003    0.122    0.003 {method 'recv_into' of '_socket.socket' objects}
 161/4    0.001    0.000    0.105    0.026 <frozen importlib._bootstrap>:966(_find_and_load)
 161/4    0.001    0.000    0.105    0.026 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)
 148/4    0.001    0.000    0.104    0.026 <frozen importlib._bootstrap>:651(_load_unlocked)
 120/4    0.000    0.000    0.104    0.026 <frozen importlib._bootstrap_external>:672(exec_module)
 193/4    0.000    0.000    0.103    0.026 <frozen importlib._bootstrap>:211(_call_with_frames_removed)

2. The following is the output from parallel.py:

(1000, 0, 1000, 0.06710124015808105)
(1000, 0, 1000, 0.12065792083740234)
(1000, 0, 1000, 0.12815380096435547)
Total elapsed time: 0.164222 seconds

Running cProfile on parallel.py produces the following:

74206 function calls (72390 primitive calls) in 0.298 seconds

Ordered by: cumulative time

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
 138/1    0.006    0.000    0.298    0.298 {built-in method builtins.exec}
     1    0.000    0.000    0.298    0.298 parallel.py:4(<module>)
    56    0.141    0.003    0.141    0.003 {method 'acquire' of '_thread.lock' objects}
    15    0.000    0.000    0.112    0.007 threading.py:1062(_wait_for_tstate_lock)
     3    0.000    0.000    0.112    0.037 threading.py:1024(join)
 161/5    0.001    0.000    0.103    0.021 <frozen importlib._bootstrap>:966(_find_and_load)
 161/5    0.000    0.000    0.103    0.021 <frozen importlib._bootstrap>:936(_find_and_load_unlocked)
 148/5    0.001    0.000    0.102    0.020 <frozen importlib._bootstrap>:651(_load_unlocked)
 120/5    0.000    0.000    0.102    0.020 <frozen importlib._bootstrap_external>:672(exec_module)
 193/5    0.000    0.000    0.101    0.020 <frozen importlib._bootstrap>:211(_call_with_frames_removed)

Notice that the total number of function calls was reduced by a factor of 3

3. Overall, the runtime was reduced from ~0.22 seconds to ~0.16 seconds, about a
30% reduction. Based on these results, I would say it is definitely worthwhile to
switch from a linear to a parallel implementation when processing HP Norton data.

4. In terms of contention, problems could occur if all threads were writing to the
same database. In this case, because we are writing to a separate database with
each thread, we are protected.
