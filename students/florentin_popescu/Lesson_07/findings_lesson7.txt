Notes for Lesson 7

(1) I updated the csv file generator to produce 1000 records in each customer, product and rental file. 

(2) Initially I inserted records into MongoDB one by one via insert_one() method (commented in script), but I observed that using insert_many() significantly speeds up the insertion (e.g., 99 milliseconds for linear insertion of customer file using insert_many() vs. 594 milliseconds via looping through rows in the file and using insert_one() - run example commented at the end of database_linear.py).    

(3) The time for linear insertion of customer and product files were comparable; 99 milliseconds for customers and 71 milliseconds for products. The total script runtime was 1 second and 176 milliseconds. CPU usage recorded at 23.2%.  

(4) For parallel insertion I implemented threading and concurrent-futures, side by side. CPU usage for both methods was comparable, 34.7% for threading and 35.6% for concurrent-futures. Insertion of customer file via threads took about 76 milliseconds while for products it took 60 milliseconds. Concurrent-futures implementation took a bit longer; 84 milliseconds insertion time for customers and 118 milliseconds for products (run example commented at the end of database_parallel_thread_futures.py).

(5) Parallel insertion via threading was faster than linear insertion by about 23% in insertion time for customer file and 15% in insertion time for product file. Parallel insertion with concurrent-futures was slightly faster than linear insertion by about 15% for customer file, but it took longer by about 66% for product file.   


Recommendation to management: 

I would recommend using parallel version with threading since it leads to faster insertion. However, if data is large, the management may select either threading or concurrent-futures, depending on processing resources on available computer architecture*.   


Contention notes:

(1) To avoid contention I implemented looks which have been released after insertion via threading. The locks helped avoiding simultaneous access of data from files. While locks leads to less efficient programs, they are needed to avoid data racing when lots of data need to be shared. An alternative option to locks is the usage of condition variables, e.g., a variable used by the thread to wait for an event generated by another thread or a timer. Strictly speaking, condition variables do not prevent data races, but they save us from having to introduce shared data that may become a source of data racing.  

(2) Contention has not occurred during insertion of records into MongoDB because the parallel script inserted only customer and product files, which are independent files (they have no common keys). If the script was also inserting rental file, which is a derived file, contention would have been possible because each rental id in the rental file has associated product and customer ids. Some ids from rental file may have been inserted before their associated customer and product ids. Although, MongoDB does not enforce constraints on foreign keys, it is safely to import at first independent files and, after the load is completed, import derived files.    

         
*Note: 
The results shown above for CPU time and runtime for linear and parallel insertion were obtained running the scripts on a 16GB ram, 250GB SSD, 2-core Intel-i5-6300U HP computer.
  